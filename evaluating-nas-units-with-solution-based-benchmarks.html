<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Evaluating NAS Units with Solution-Based Benchmarks - BlogVibe</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content="Recently, I had the opportunity to visit a leading NAS vendor and provide some insights on how we evaluate NAS units. In particular, the talk dealt with the importance of NAS units in real-world applications and how to model them from a benchmarking perspective."><meta name=robots content="index,follow,noarchive"><meta property="og:title" content="Evaluating NAS Units with Solution-Based Benchmarks"><meta property="og:description" content="Recently, I had the opportunity to visit a leading NAS vendor and provide some insights on how we evaluate NAS units. In particular, the talk dealt with the importance of NAS units in real-world applications and how to model them from a benchmarking perspective."><meta property="og:type" content="article"><meta property="og:url" content="/evaluating-nas-units-with-solution-based-benchmarks.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-06-05T00:00:00+00:00"><meta property="article:modified_time" content="2024-06-05T00:00:00+00:00"><meta itemprop=name content="Evaluating NAS Units with Solution-Based Benchmarks"><meta itemprop=description content="Recently, I had the opportunity to visit a leading NAS vendor and provide some insights on how we evaluate NAS units. In particular, the talk dealt with the importance of NAS units in real-world applications and how to model them from a benchmarking perspective."><meta itemprop=datePublished content="2024-06-05T00:00:00+00:00"><meta itemprop=dateModified content="2024-06-05T00:00:00+00:00"><meta itemprop=wordCount content="2104"><meta itemprop=keywords content><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/mainroad/css/style.css><link rel="shortcut icon" href=./favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=./index.html title=BlogVibe rel=home><div class="logo__item logo__text"><div class=logo__title>BlogVibe</div></div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Evaluating NAS Units with Solution-Based Benchmarks</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2024-06-05T00:00:00Z>June 05, 2024</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=./categories/blog/ rel=category>blog</a></span></div></div></header><div class="content post__content clearfix"><p>Recently, I had the opportunity to visit a leading NAS vendor and provide some insights on how we evaluate NAS units. In particular, the talk dealt with the importance of NAS units in real-world applications and how to model them from a benchmarking perspective.</p><p>Meanwhile, as the timing of this talk overlaps with some of our upcoming NAS reviews, we decided to open up the presentation to our readers as well in order to give all of you a look at some of what goes on behind the scenes here at AnandTech. We don't often get the opportunity (or time) to write much about our benchmarking selection process, so for us this is a chance to discuss a bit more about how we put together our tests. In addition to serving as a reference for the testing methodology in our reviews, we wanted to present the rationale behind our benchmarking routines and give you guys a chance to offer some feedback in the process.</p><h2>Introduction and Evaluation Metrics</h2><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-0_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>The presentation started off with a little bit of background information about myself as well as our experience with covering NAS units. We then moved on to a brief discussion of the marketing aspects associated with any NAS unit. An important aspect from a review perspective is that there are multiple units in the market targeting different market segments, and it is not always possible to do apples-to-apples comparison. In addition, a NAS unit receiving stellar reviews from the press doesn't necessarily get automatic market success. We believe success is often dictated by channel presence and bundling deals (particularly in the SMB market).</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-2.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-3.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Evaluation metrics can fall under two categories - subjective and objective. The former refers to aspects such as the management web UI. For example, Synology adopts a desktop-like UI, while QNAP and Asustor adopt a mobile OS-like model. Netgear and Western Digital, on the other hand, have a widget-based approach with a rolling icon menu at the top. Different users have different preferences, and it is difficult for a reviewer to point out any particular interface as being the better one without bringing personal opinion into the picture. Another aspect is the mobile app strategy. While vendors like QNAP and Synology have multiple mobile apps for different NAS functionalities (like multimedia streaming, management etc.), ones like Western Digital have a single unified app for all the user requirements. Again, different users might have different preferences in this area. Finally, we have various value-added services. Again, the user-experience with these features is difficult to cover objectively (other than pointing out any obvious bugs in them). In any case, these value-added services are fast becoming marketing checklists. Users interested in any particular service would do well to research that aspect thoroughly (by, say, going over forum posts dealing with the aspect) rather than rely on press reviews. In most cases, these capabilities get feature updates and bug fixes more often compared to the core firmware.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-4.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>On the other hand, objective metrics such as throughput and latency as well as power consumption numbers are more straightforward to analyze. However, reviewers need to keep certain aspects in mind, and we covered those later on in the talk.</p><h2>Power Efficiency and Failure Handling</h2><p>Readers of our NAS reviews already know about our detailed power consumption and RAID migration / rebuild testing. We presented a step-by-step account in order to shed further light on our evaluation procedure.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-5.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-6.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>In terms of failure handling, we believe NAS vendors can differentiate by providing Windows-based tools for recovering data from arrays created on their NAS units. The current easy-to-use options such as UFS Explorer are not free, and a free tool from the NAS vendor would be great for consumers when the NAS suffers a hardware failure, but the disks are in good condition.</p><h2>Performance Evaluation</h2><p>Many reviewers adopt file copy tests as a measure of performance, but that doesn't serve to test out multi-client performance or use-cases such as office productivity. There are number of options available for benchmarking, but most of the open source ones utilize artificial workloads. Even we have been guilty of using benchmarks such as IOMeter and IOZone and presenting results from running artificial workloads on various NAS units. On the other hand, we have commercial load testing tools such as Login VSI (for testing virtualization loads) and hIOmon for replaying and analyzing performance with actual system traces. LoadDynamiX is an appliance that can be used to stress storage nodes, but, again, it is easier to run artificial workload traces (with additional metadata access) on them rather than real-life traces.</p><p>The Intel NAS Performance Toolkit (NASPT) is undoubtedly the most popular benchmarking tool amongst reviewers handling NAS units. However, it is prone to misuse. I have often seen transfer rates obtained using different disks on different NAS units used as comparison points. It is essential that the storage media as well as the client used to run the tests be the same across all NASPT evaluations. We covered NASPT in detail later on in the presentation.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-7.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Moving on to the marketing aspects associated with performance, we find that many vendors just provide read and write transfer rates for a pre-specified configuration. Unfortunately, there is no consistency across vendors and in any case, this metric is easy to manipulate in order to mislead consumers. With increasing prevalence of multiple clients of different types, these transfer rates are almost never going to be experienced by the average end-user. The metric that actually matters for stressful workloads (most business use-cases) is IOPS. However, it is not easy to convey the importance of IOPS to home users, as they have no idea of what the requirements for their workload are going to be. It is a situation that reviewers could do well to address.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-8.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>At AnandTech, we focus on three main services - CIFS, NFS and iSCSI - across both Windows 7 and Linux (CentOS / Ubuntu). We used to rely on Intel NASPT in the early days for CIFS and iSCSI. Linux / NFS utilized IOZone. Unfortunately, they are not great choices for multi-client testing.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-9.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>We decided to focus on multi-client testing a few years back and set up configurations similar to the ones depicted in the slide below. The number of VMs that could be simultaneously active on the NAS testbed could be up to 25.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-10.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Our workload / benchmark program of choice was four artificial traces with IOMeter. We chose IOMeter partly because of the in-built synchronization across multiple clients. Unfortunately, all our graphs presented bandwidth numbers and latencies that were difficult for the average end-user to relate to.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-11.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>The typical NAS user wants a review to provide clear-cut answers for questions such as: "How many simultaneous videos can the NAS stream out?", "How many IP cameras can be reliably recorded on the NAS at the same time?". In our opinion, these 'solution-based metrics' are the holy grail of any NAS evaluation, and that dictated the approach we have been adopting in our recent NAS reviews.</p><h2>Intel NASPT and AnandTech's Extensions</h2><p>Intel NASPT was first released at IDF in 2007. It adopted a real-world workload trace replay approach. In those days, NAS units struggled to provide USB 2.0 speeds despite being equipped with GbE LAN ports. For extensive workload behavior analysis, NASPT also shipped with a visualizer. NAS units have improved by leaps and bounds since then, and saturating network links is now hardly difficult for most NAS units. Despite being actively used by reviewers, Intel dropped support for NASPT as it had served its original purpose - targeting improvements in NAS units meant for home and SOHO (small office, home office) use. Fortunately, Intel decided to release the source code and this allowed us to build custom versions that could be used on modern systems.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-12.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>NASPT utilizes traces that were recorded on real systems during actual operation. A summary of the various aspects of each trace is provided below.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-13.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>How could Intel NASPT be used to address our eventual goal of the determination of solution-based metrics? We know that the workload traces, despite being a bit dated, are from real-world applications. The internal trace replay component is still a valid tool. We took advantage of these two portions of NASPT and added a wrapper to farm out the trace replay to multiple clients and also synchronize their execution. Determination of the 'solution-based metric' then boiled down to the number of clients that could provide acceptable performance.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-14.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-15.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>We cited an example from our recent review of the Netgear ReadyNAS RN202. In the 'Folder Copy from NAS' workload, we found that the transfer rate saturated beyond 5 clients around 560 Mbps (despite the theoretical link-aggregated bandwidth being 2 Gbps). The average response time also starts to show a steep slope after 5 clients. We could interpret the graph as suggesting that the system (RN202 + 2x WD4000FYYZ drives) could support up to 5 clients performing folder copies to the NAS simultaneously.</p><h2>SPEC SFS 2014</h2><p>Our experiments with the concept of business metrics and solution-based benchmarking was actually triggered by the SPEC SFS 2014 benchmark. SPEC's SFS benchmarks have been around since 1993. The latest release (SPEC SFS 2014) can benchmark both CIFS and NFS shares. The benchmark is based quite a bit on IOZone and the workload traces that are run by the benchmark have been collected on live systems by various vendors participating in the benchmark. Unlike Intel NASPT, the SPEC SFS 2014 benchmark has been designed from the ground up to provide concrete answers for the solution-based metrics that can be supported by a storage node. In order to aid in the decision process, each benchmark run records various business metrics such as the achieved operation rate, throughput and response times.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-16.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>A summary of the various aspects of each trace is provided below. The VDA workload includes contribution from IBM while Microsoft and EMC contributed to the VDI one. NetApp provided the SWBUILD workload, while the DB workload was created with contributions from NetApp and Oracle.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-17.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>SPEC SFS 2014 automatically parses the results from each benchmark run and provides us with a single load point (could be the maximum number of clients tested) and an associated average latency as an indication of the quality of service. The success criteria at each load point is based on the collected business metric at that point as well as the requirements with respect to the oprate and acceptable workload variance across the component processes.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-18.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>The SPEC SFS 2014 benchmark requires at least 10 load points for a publishable result. It is designed for large scale systems. Almost all 2-, 4- or 8-bay NAS units fitted with 7200 RPM SATA drives fail this requirement. However, with SSDs, the results should be much more interesting, as we will see in future reviews.</p><h2>Future Work & Concluding Remarks</h2><p>We took a break from reviewing NAS units after publishing our Western Digital DL4100 in March 2015. In the mean time, we were able to get our 'solution-based benchmarking' strategy to a state fit enough to use for published reviews. However, we still have a number of avenues left to explore. It would be nice to update the NASPT traces with workloads corresponding to, say, 4K video playback or backup jobs. Investigation into hypervisor effects would be an interesting thing to do (as we use virtual machines with dedicated network links for simulating clients). Many NAS vendors are supporting SMB multi-channel now, and it would be prudent to move from Windows 7 to Windows 10 as the guest OS for the VMs soon. The most important task, however, is to formalize the determination of acceptable business metrics for the NASPT workloads in a manner similar to what has been done for the SPEC SFS 2014 workload traces.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9750/NAS-Eval-19.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>In terms of hardware upgrades, the current testbed is being operated in a residential setting, and I am always looking to drive down the power consumption and the noise. In particular, the Netgear XS712T (12x 10GBASE-T smart switch) has a 50 dB+ official rating, and it would be nice to have a quieter alternative. The other aspect is the NAS testbed itself. We are currently using a 2x Intel Xeon E5-2630L system. However, Xeon-D systems with the integrated 10GBASE-T ports are looking very attractive right now in terms of allowing us to operate more virtual machines within the same power budget.</p><p>As always, we look forward to more feedback on our strategy as well as additional suggestions from NAS vendors as well as readers. A PDF copy of the full presentation is available in the source link below.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZIZ4gY9onK%2BZnKqutbXNoGSnmaNiwq%2B106xksKGknXq0u8uuq6KnnmKvor%2FEnWSbnZ6Yta6t0aSq</p></div></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=./david-shapiro-economist.html rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Fame | David Shapiro (economist) net worth and salary income estimation Jan, 2024</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=./conor-mcgregor.html rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Conor McGregor (Boxer) Wikipedia, Bio, Age, Height, Weight, Wife, Net Worth, Career, Facts</p></a></div></nav></div><aside class=sidebar><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./all-about-the-wife-of-joe-montana.html>All About The Wife Of Joe Montana</a></li><li class=widget__item><a class=widget__link href=./best-servants-in-fate-grand-order.html>Best Servants in Fate Grand Order</a></li><li class=widget__item><a class=widget__link href=./catherine-zeta-jones-michael-douglas-split-everything-we-know-past-temporary-breakup.html>Catherine Zeta-Jones and Michael Douglas once temporarily split - everything we know about their pas</a></li><li class=widget__item><a class=widget__link href=./english-actress-bella-ramsey-hobby-acting-career-hbo-game-of-thrones-lyanna-mormont.html>English Actress, Bella Ramsey hobby for acting led her in Acting since her early life. Starting a ca</a></li><li class=widget__item><a class=widget__link href=./jane-fonda-throws-award-at-justine-triet-at-2023-cannes-film-festival.html>Jane Fonda throws award at director Justine Triet at 2023 Cannes Film Festival</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./categories/blog/>blog</a></li></ul></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2024 BlogVibe.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=https://assets.cdnweb.info/hugo/mainroad/js/menu.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>